{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c18639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¬ AI å›æ‡‰ï¼š\n",
      "{'model': 'gemma3:1b', 'created_at': '2025-07-25T22:01:03.916740705Z', 'response': '{\\n\"è§£é‡‹ï¼š\":\"Pythonçš„å‡½å¼å°±åƒæ˜¯ç¨‹å¼çš„æŒ‡ä»¤ï¼Œä½ å¯ä»¥æŠŠå®ƒæƒ³åƒæˆä¸€å€‹å°å°çš„ä»»å‹™ã€‚ä½ å‘Šè¨´å‡½å¼è¦åšä»€éº¼ï¼Œå‡½å¼å°±æœƒåŸ·è¡Œï¼Œä¸¦ç”¢ç”Ÿçµæœã€‚\"\\n\\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n', 'done': False}\n",
      "{\n",
      "\"è§£é‡‹ï¼š\":\"Pythonçš„å‡½å¼å°±åƒæ˜¯ç¨‹å¼çš„æŒ‡ä»¤ï¼Œä½ å¯ä»¥æŠŠå®ƒæƒ³åƒæˆä¸€å€‹å°å°çš„ä»»å‹™ã€‚ä½ å‘Šè¨´å‡½å¼è¦åšä»€éº¼ï¼Œå‡½å¼å°±æœƒåŸ·è¡Œï¼Œä¸¦ç”¢ç”Ÿçµæœã€‚\"\n",
      "\n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def chat_with_ollama(prompt: str):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": \"gemma3:1b\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": { #åƒè€ƒèªªæ˜1\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.9,\n",
    "            \"top_k\": 50,\n",
    "        },\n",
    "        \"max_tokens\": 100,\n",
    "        \"format\": \"json\",\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload)\n",
    "    result = response.json()\n",
    "    print(\"ğŸ’¬ AI å›æ‡‰ï¼š\")\n",
    "    # Print the whole result for debugging\n",
    "    print(result)\n",
    "    # Try to print the 'response' key if it exists, otherwise print possible keys\n",
    "    if \"response\" in result:\n",
    "        print(result[\"response\"])\n",
    "    elif \"message\" in result:\n",
    "        print(result[\"message\"])\n",
    "    elif \"content\" in result:\n",
    "        print(result[\"content\"])\n",
    "    else:\n",
    "        print(\"No expected key found in response. Available keys:\", result.keys())\n",
    "\n",
    "#ç¯„ä¾‹è¼¸å…¥\n",
    "chat_with_ollama(\"è«‹ç”¨ç°¡å–®çš„æ–¹å¼è§£é‡‹ä»€éº¼æ˜¯Pythonçš„å‡½å¼ï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e79444",
   "metadata": {},
   "source": [
    "### èªªæ˜1\n",
    "\n",
    "`options` ç‰©ä»¶å°è£äº†å°æ–¼ç”Ÿæˆæ¨¡å‹è¡Œç‚ºçš„ä¸‰å€‹é—œéµèª¿æ•´åƒæ•¸ï¼š`temperature`ã€`top_p` ä»¥åŠ `top_k`ã€‚é€éé€™äº›è¨­å®šï¼Œæˆ‘å€‘å¯ä»¥æ›´ç²¾ç´°åœ°æ§åˆ¶æ¨¡å‹åœ¨ç”¢ç”Ÿæ–‡å­—æ™‚çš„éš¨æ©Ÿç¨‹åº¦èˆ‡å¤šæ¨£æ€§ï¼Œä»¥é”åˆ°æ›´ç¬¦åˆéœ€æ±‚çš„è¼¸å‡ºé¢¨æ ¼ã€‚\n",
    "\n",
    "`temperature`ï¼ˆæº«åº¦ï¼‰åƒæ•¸è¨­å®šç‚º 0.7ï¼Œè¡¨ç¤ºåœ¨æŒ‘é¸ä¸‹ä¸€å€‹å­—å…ƒæˆ–è©å½™æ™‚ï¼Œæœƒæ ¹æ“šæ¨¡å‹é æ¸¬æ©Ÿç‡åˆ†ä½ˆåšæº«åº¦ç¸®æ”¾ã€‚æº«åº¦è¶Šæ¥è¿‘ 1ï¼Œç”Ÿæˆçµæœè¶Šéš¨æ©Ÿã€å¤šæ¨£ï¼›ç•¶æº«åº¦é™ä½æ™‚ï¼Œç”Ÿæˆæ›´å‚¾å‘æ–¼é«˜æ©Ÿç‡é¸æ“‡ï¼Œè¼¸å‡ºçµæœè¼ƒç‚ºä¿å®ˆä¸”é‡è¤‡æ€§å¢åŠ ã€‚è¨­å®šç‚º 0.7 èƒ½åœ¨éš¨æ©Ÿæ€§èˆ‡ç©©å®šæ€§é–“å–å¾—å¹³è¡¡ã€‚\n",
    "\n",
    "`top_p`ï¼ˆåˆç¨± nucleus samplingï¼‰è¨­ç‚º 0.9ï¼Œä»£è¡¨æ¯æ¬¡ç”Ÿæˆæ™‚åƒ…è€ƒæ…®ç´¯ç©æ©Ÿç‡å‰ 90% çš„å€™é¸è©å½™ã€‚æ›è¨€ä¹‹ï¼Œæ¨¡å‹å…ˆå°‡æ‰€æœ‰å€™é¸ä¾æ©Ÿç‡ç”±é«˜åˆ°ä½æ’åºï¼Œç„¶å¾Œå¾æ©Ÿç‡ç¸½å’Œé”åˆ° 0.9 çš„è©å½™å­é›†ä¸­é€²è¡Œéš¨æ©ŸæŠ½æ¨£ã€‚é€™ç¨®æ–¹æ³•å¯é¿å…åªé—œæ³¨æœ€é«˜æ©Ÿç‡è€Œå¿½ç•¥å…¶ä»–åˆç†é¸é …ï¼Œä¹Ÿèƒ½è‡ªå‹•èª¿æ•´æŠ½æ¨£ç¯„åœä»¥æŠ‘åˆ¶æ¥µä½æ©Ÿç‡çš„ã€Œå™ªéŸ³ã€è¼¸å‡ºã€‚\n",
    "\n",
    "`top_k` åƒæ•¸è¨­ç½®ç‚º 50ï¼Œè¡¨ç¤ºåœ¨æŠ½æ¨£æ™‚åƒ…å¾é æ¸¬æ©Ÿç‡æœ€é«˜çš„å‰ 50 å€‹è©å½™ä¸­é¸æ“‡ä¸‹ä¸€æ­¥çµæœã€‚é€™æ˜¯åœ¨é™åˆ¶æœç´¢ç©ºé–“å¤§å°ã€æé«˜é‹ç®—æ•ˆç‡èˆ‡å“è³ªæ§åˆ¶çš„å¸¸è¦‹åšæ³•ã€‚çµåˆ `top_p` èˆ‡ `top_k` ä½¿ç”¨ï¼Œèƒ½é€²ä¸€æ­¥å¹³è¡¡å¤šæ¨£æ€§èˆ‡ç©©å®šæ€§ï¼š`top_k` ç¢ºä¿å€™é¸é›†ä¸è¶…éä¸€å®šè¦æ¨¡ï¼Œ`top_p` å‰‡ä¾å¯¦éš›æ©Ÿç‡åˆ†ä½ˆå‹•æ…‹ä¿®å‰ªé›†å…§è©å½™ã€‚\n",
    "\n",
    "ç¶œåˆè€Œè¨€ï¼Œé€™ä¸‰é …åƒæ•¸å…±åŒç‚ºç”Ÿæˆæ¨¡å‹æä¾›äº†å¤šå±¤æ¬¡çš„éš¨æ©Ÿèˆ‡ç¯©é¸æ©Ÿåˆ¶ã€‚ä¾æ“šä¸åŒæ‡‰ç”¨å ´æ™¯ï¼ˆå¦‚å°è©±ç³»çµ±ã€æ–‡ç« æ’°å¯«æˆ–ç¨‹å¼ç¢¼ç”Ÿæˆï¼‰ï¼Œå¯å¾®èª¿é€™äº›å€¼ä»¥ç²å¾—æ›´ç¬¦åˆéœ€æ±‚çš„çµæœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0082f63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­¡è¿ä½¿ç”¨æœ¬åœ°ç«¯ LLM èŠå¤©æ©Ÿå™¨äººï¼ˆè¼¸å…¥ q é›¢é–‹ï¼‰\n",
      "ğŸ’¬ AI å›æ‡‰ï¼š\n",
      "{'model': 'gemma3:1b', 'created_at': '2025-07-25T22:14:27.35581321Z', 'response': '{\\n\"response\": \"å¤©ç©ºä¹‹æ‰€ä»¥æ˜¯è—çš„ï¼Œä¸»è¦æ˜¯å› ç‚ºä¸€ç¨®å«åš**ç‘åˆ©æ•£å°„ (Rayleigh scattering)** çš„ç¾è±¡ã€‚ ç°¡å–®ä¾†èªªï¼Œå¤ªé™½å…‰ç©¿éå¤§æ°£å±¤æ™‚ï¼Œæœƒèˆ‡ç©ºæ°£ä¸­çš„å¾®å°ç²’å­ï¼ˆä¸»è¦æ˜¯æ°®æ°£å’Œæ°§æ°£ï¼‰ç™¼ç”Ÿç¢°æ’ã€‚ ç”±æ–¼é€™äº›ç²’å­å°ºå¯¸éå¸¸å°ï¼Œç¢°æ’æœƒå°‡å¤ªé™½å…‰æ•£å°„åˆ°ä¸åŒçš„æ–¹å‘ã€‚**è—å…‰ï¼ˆæ³¢é•·è¼ƒçŸ­ï¼‰æ›´å®¹æ˜“è¢«æ•£å°„ï¼Œå› æ­¤è¢«æ•£å°„åˆ°å¤©ç©ºçš„æ¯å€‹æ–¹å‘ã€‚**\"\\n}', 'done': True, 'done_reason': 'stop', 'context': [105, 2364, 107, 141370, 95202, 237026, 241339, 236918, 106, 107, 105, 4368, 107, 236782, 107, 236775, 6275, 1083, 623, 141370, 132414, 237026, 241339, 236918, 236900, 74836, 27502, 120460, 100083, 1018, 240046, 237766, 150341, 568, 30958, 53700, 19389, 62902, 10363, 121887, 236924, 236743, 74624, 94757, 236900, 83700, 237914, 239409, 238124, 237110, 239471, 239614, 237479, 236900, 238003, 238693, 235450, 12870, 238477, 237369, 166747, 237221, 74836, 243140, 239471, 237206, 240514, 239471, 237214, 90972, 181044, 236924, 236743, 92793, 52426, 166747, 67868, 13869, 237369, 236900, 181044, 238003, 239079, 83700, 237914, 150341, 237238, 35078, 25718, 236924, 1018, 241339, 237914, 237221, 238663, 237953, 239350, 238906, 237214, 186897, 237759, 150341, 236900, 23041, 237759, 150341, 237238, 141370, 236918, 117680, 25718, 236924, 1018, 236775, 107, 236783], 'total_duration': 28573776231, 'load_duration': 336781457, 'prompt_eval_count': 14, 'prompt_eval_duration': 768334282, 'eval_count': 104, 'eval_duration': 26656140121}\n",
      "{\n",
      "\"response\": \"å¤©ç©ºä¹‹æ‰€ä»¥æ˜¯è—çš„ï¼Œä¸»è¦æ˜¯å› ç‚ºä¸€ç¨®å«åš**ç‘åˆ©æ•£å°„ (Rayleigh scattering)** çš„ç¾è±¡ã€‚ ç°¡å–®ä¾†èªªï¼Œå¤ªé™½å…‰ç©¿éå¤§æ°£å±¤æ™‚ï¼Œæœƒèˆ‡ç©ºæ°£ä¸­çš„å¾®å°ç²’å­ï¼ˆä¸»è¦æ˜¯æ°®æ°£å’Œæ°§æ°£ï¼‰ç™¼ç”Ÿç¢°æ’ã€‚ ç”±æ–¼é€™äº›ç²’å­å°ºå¯¸éå¸¸å°ï¼Œç¢°æ’æœƒå°‡å¤ªé™½å…‰æ•£å°„åˆ°ä¸åŒçš„æ–¹å‘ã€‚**è—å…‰ï¼ˆæ³¢é•·è¼ƒçŸ­ï¼‰æ›´å®¹æ˜“è¢«æ•£å°„ï¼Œå› æ­¤è¢«æ•£å°„åˆ°å¤©ç©ºçš„æ¯å€‹æ–¹å‘ã€‚**\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def chat_with_ollama(prompt: str):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": \"gemma3:1b\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": { #åƒè€ƒèªªæ˜1\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.9,\n",
    "            \"top_k\": 50,\n",
    "        },\n",
    "        \"max_tokens\": 100,\n",
    "        \"format\": \"json\",\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload)\n",
    "    result = response.json()\n",
    "    print(\"ğŸ’¬ AI å›æ‡‰ï¼š\")\n",
    "    # Print the whole result for debugging\n",
    "    print(result)\n",
    "    # Try to print the 'response' key if it exists, otherwise print possible keys\n",
    "    if \"response\" in result:\n",
    "        print(result[\"response\"])\n",
    "    elif \"message\" in result:\n",
    "        print(result[\"message\"])\n",
    "    elif \"content\" in result:\n",
    "        print(result[\"content\"])\n",
    "    else:\n",
    "        print(\"No expected key found in response. Available keys:\", result.keys())\n",
    "\n",
    "    \n",
    "def chat_loop():\n",
    "    print(\"æ­¡è¿ä½¿ç”¨æœ¬åœ°ç«¯ LLM èŠå¤©æ©Ÿå™¨äººï¼ˆè¼¸å…¥ q é›¢é–‹ï¼‰\")\n",
    "    while True:\n",
    "        user_input = input(\"ğŸ‘¤ ä½ èªªï¼š\")\n",
    "        if user_input.lower() == 'q':\n",
    "            break\n",
    "        chat_with_ollama(user_input)\n",
    "\n",
    "chat_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "line_bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
